from langchain_community.chat_models import ChatTongyi
from langchain_core.prompts import (ChatPromptTemplate, MessagesPlaceholder, 
    HumanMessagePromptTemplate)
from langchain_core.messages import SystemMessage, AIMessage, HumanMessage
from langchain_core.output_parsers import StrOutputParser
from langchain.prompts.example_selector import SemanticSimilarityExampleSelector
from dotenv import load_dotenv, find_dotenv
from langchain_deepseek import Deepseek, ChatDeepseek

load_dotenv(find_dotenv())

llm = ChatTongyi()

prompt = ChatPromptTemplate.from_messages([
  SystemMessage(content='ä½ æ˜¯ä¸€ä¸ªèªæ˜ã€å‹å–„ä¸”ä¹äºåŠ©äººçš„AIåŠ©æ‰‹ã€‚'),
  MessagesPlaceholder(variable_name='chat_history'),
  HumanMessagePromptTemplate.from_template('{question}')
])

messages = prompt.format_messages(
  chat_history=[
    HumanMessage(content='ä½ å¥½ï¼Œæˆ‘å«sonera, å¾ˆé«˜å…´è§åˆ°ä½ ï¼'),
    AIMessage(content='ä½ å¥½ï¼ŒSoneraï¼æˆ‘ä¹Ÿå¾ˆé«˜å…´è§åˆ°ä½  ğŸ˜Š')
  ],
  question='è¿˜è®°å¾—æˆ‘å«ä»€ä¹ˆåå­—å—ï¼Ÿ'
)

response = llm.invoke(messages)

print(response.content)
